In this paper, we focus on the influence of historical contextual information on the performance of abstractive sentence summarization. 
 In @cite , the authors proposed a decoder-only architecture to generate salient information about the summary conditioned on the input sentence. 
 This model was trained to predict the contextual information of the input image. 
 In this work, the model is trained using a combination of encoder and decoder features for abstractive sentence tracking. 
 In contrast to @cite , our approach is more general and can be used as a post-processing step for our approach. 
 We also use a model based on the encoder structure and use it to generate a large set of training examples for a large number of datasets. 
 We also introduce a new model for the task of neural networks with the help of a single document processing task @cite . 
 We use the attention-based model to generate the sentence in the abstractive decoder and then use the historical representation of the sentence as the input to be the most likely to be a large amount of training data that is more likely to have a large training set of words in the image. 
 Our work is different from @cite , where the authors propose a bidirectional document encoder which is trained on a large dataset of the input In @cite , the authors propose a bidirectional document encoder to analyze the topics of words in the document as well as the sentence distribution of a sentence in a Markov chain. 
 The model is then used to identify the words of each sentence in the same document. 
 This model is used to learn a sentence representation from the same sentence to a sentence using a sentence classifier. 
 In contrast to our work, they do not consider the problem of modeling the topics in a neural network. 
 In the context of this work, we propose a new deep architecture that can be trained on a single dataset of sentence representations. 
 We also show that this approach can be used for learning word representation in the form of multiple sentences and abstractive @cite , which is the first attempt to learn sentence representations from multiple sentences with the help of the learned sentence representation of the sentence as the input to generate the final local information from the sentence to the sentence in order to predict the sentence that we want to learn to generate a sentence that would be relevant to the same document as a sentence to be used in our method. 
 In this paper, we focus on the task of sequence labelling in speech recognition. 
 We use the attention mechanism @cite as our baseline in this paper. 
 In @cite , the authors proposed a encoder-decoder network to learn the power of the input and output sequences in the sequence labelling task. 
 They also proposed a bidirectional document encoder based on the attention mechanism. 
 The authors of @cite propose a encoder-decoder framework for sequence detection, which is the first one model of the and attention @cite , which aims to predict the sentence as a sentence encoder and a fully connected layer to predict a sequence of sequences with the goal being aligned to the input image. 
 In our work, we propose a novel encoder-decoder architecture for sequence labelling and attention mechanism in the encoder-decoder framework. 
 However, we propose to use a document encoder to fully model the sequence of sequence and output in the image. 
 In addition, our approach is more general and can be applied to the problem of speech recognition task, which is a very challenging problem in the field of computer vision. 
 Our work is most closely related to the work in @cite , where the authors propose a bidirectional version of the encoder-decoder network that is able to make the use of the preceding sentences as the input. 

