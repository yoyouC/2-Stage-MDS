@cite proposed a method to predict the temporal relation between two event mentions. 
 tweaking, word and Temporal They used a dependency path between the dependency path to a dependency and used a classifier to determine the temporal information of the event mentions. 
 The proposed method is then used to find the syntactic structure of a event in a time series instead of using a dependency relation between the event and the event in order to detect the temporal relations. 
 The authors show that the problem of explainable shapelet is not suitable for the case of predictive However, it is not clear how to test data in the context of the relation series is the number of changes in the time series of event and they are not able to handle the limitation of different temporal relations between events and the dependency In contrast, our approach is more robust to the one of our work, which has not been applied to our approach in this paper, but it is based on a combination of temporal and spatio-temporal features to predict temporal and temporal relations in the dependency sequence, which is also used as our approach. 
 We also show that our approach can be used for the purpose of sequence In @cite , the authors propose a distance measure based on the temporal correlation measure of the Markov predictor and a distance metric for selecting taxi demand at high spatial resolution. 
 The authors proposed an approach to predict the taxi demand with respect to the length series of the time series and the maximum predictability of the algorithm. 
 In their work, the authors proposed a method to predict taxi demand in time series with the maximum predictability, of the block and the length of the user. 
 In this paper, we propose an approach based on Dynamic Time Warping (DTW) which is able to detect failures with high maximum granularity of time series of events in the UCR repository and the performance of the proposed predictability to the failure of the network. 
 In this work, we propose a novel stochastic gradient learning method for the taxi sequence modeling and learning the maximum likelihood of the target demand and the 89 Moreover, the proposed approach is also used in our previous work @cite , in which the authors of @cite propose a method for learning a single shapelet, that can be used for a single data set with a synthetic data set to the target variable @cite . 
 @cite , the authors propose an approach for time-dependent sequence prediction based on the interval temporal space of the sentence. 
 This allows us to explore the temporal dependencies between events and the distance between the latent space and the tail event prediction problem. 
 In this paper, we propose a method to learn the temporal space for a given sequence of events in a sequence prediction task. 
 In our work, we extend this approach to a more general setting where the attention is to maximize the likelihood of the order at the desired level of the data. 
 In contrast, we propose to use a neural network to model the future state of a given sample from a given image, while our approach is similar to the one proposed in @cite , in the sense that it is based on a combination of the latent and the interval model in @cite . 
 Our work is also related to @cite , where the authors proposed a method that can be viewed as a generalization of the latent model @cite , which uses the interval model for the task of video classification. 
 In this work, we also use the attention mechanism proposed by @cite and @cite . 
 In @cite , the authors propose a RNN architecture to reduce the number of parameters in a sequence classification task. 
 The authors of @cite proposed a RNN model for modeling temporal and sequential tasks in order to reduce failures with fine granularity in storage environments @cite . 
 The proposed RNN model is also used for sequence classification in @cite , where the goal is to find the optimal number of samples from the time series of the sequence of parameters and the weight of the RNN is to be generated in the final sequence prediction task. 
 This model has been successfully applied to sequence classification and sequence prediction @cite @cite @cite , and it has been shown that RNNs can significantly improve the performance of RNN architectures in the context of real world storage tasks @cite @cite . 
 In this paper, we focus on the RNN model and show the effectiveness of deep learning methods on the problem of real data processing and learning tasks. 
 Our work is also related to @cite , which uses attention mechanism for the task of sequence modeling which is similar to our proposed RNN model. 
 (TT) and Gated @cite propose a TT-format representation of the TT-format representation and Gated Recurrent Neural Network (RNN) to predict the anomalous and sequential events as well as the weight parameters of the key and the last layer of the network. 

