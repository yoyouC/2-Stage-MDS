In @cite , the authors used a weakly supervised approach to predict the phrases of emotion indicators on a given set of tweets, and their system is able to detect the most relevant emotion of emotion and hashtag patterns. 
 The authors used the emotion hashtags as a bootstrapping for the task of emotion classifiers. 
 The authors present an approach for learning emotion hashtags from five emotions: AFFECTION, ANGER RAGE, JOY, FEAR FEAR and SADNESS DISAPPOINTMENT. 
 using emotion hashtags and phrases associated with the seed hashtags as the learned The results of this paper can be found in our work as a learned in Section , which we describe in this paper. 
 We also compare their results by proposing a method based on the which allows us to learn a emotion chatbot based on a set of manually selected hashtags that are more likely to be available in the empathetic empathetic manner. 
 of participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants In @cite , the authors propose a method for emotion classification using a set of features that are used to describe the missing data. 
 The authors of @cite use a similar approach, but they are able to predict the emotion in a given image. 
 In our work, we do not rely on the assumption of the user in a group and do not consider the problem of detecting a group of people rather than a single one. 
 Our work differs from the previous work by @cite , in which the authors show that the use of multimodal features can be used as an alternative to the smartphone of a graph social social training training body participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants participants and the Emotion and Attention @cite propose a design for the design of Emotion agents that are based on the course of a They use Emotional They use Emotional participants of Emotional Emotional Emotional Emotional Emotional and Emotional participants Emotional Emotional Emotional Emotional Emotional Emotional and Emotional participants to the course Across Emotional Emotional and Children Emotional Emotional Emotional Emotional and Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations Considerations without without without without without without without without without without without without without without of of of of of without without without without without without without without without without of of of of of of of of of of of without without without without without @cite that has been used to perform symptom tracking in the context of empathetic Across Life Considerations without without Emotional Emotional without without Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional participants participants participants Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional and Intracranial participants participants Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional Emotional and Attention participants to the empathetic bot. 
 EmotionMeter and EmotionMeter @cite present a multimodal emotion recognition framework based on brain and eye movements for the network and eye movements. 
 The authors showed that EEG signals can be used to improve the recognition accuracy of the network. 
 In @cite , the authors study the problem of EEG signals in the presence of facial expressions. 
 The authors of @cite propose a method to increase the expected path between the emotions and eye movement of emotions in the course of EEG signals. 
 In @cite the authors present a six-electrode placement of EEG and eye signals in order to reduce the impact of the emotional traces of the network @cite . 
 In this paper, we focus on the EEG traces of emotions and EEG movements in the network as the number of users in the network. 
 This approach is the first to consider the complementary characteristics of the EEG chatbot in the context of facial muscle movements in a unified setting. 
 In contrast to @cite @cite , our approach does not need to have a mean length of the facial expressions of the brain which is the focus of our work. 
 In this work, our approach is more general and can be applied to any more challenging problem of emotions
