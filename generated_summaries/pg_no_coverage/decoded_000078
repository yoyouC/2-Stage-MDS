there has been a great body of work on unsupervised learning algorithms for image classification @ cite @ cite , @ cite and @ cite .
 in this work , we focus on the problem of finding a subset of the effect of a neural network that is known to be known .
 for example , in @ cite the authors show that the greedy layer-wise procedure, algorithm converges to the parameters of the optimization problem .
 @ cite propose a greedy layer-wise unsupervised learning strategy based on the usage of synthetic gradients .
 the authors of @ cite use a generative model to learn the true campaign at the end of the network , and find that the workers are able to minimize the number of individuals , and the coordination between the workers in the round-robin scheme .
 in contrast , our approach is similar to ours in the sense that the joint distribution of the locking is known .
 in the work , the authors propose a method to train a multi-layer perceptron ( mlp ) that performs well on the state of the art in the context of deep learning .
 however , this approach does not require a specification of the performance of the training procedure .
 our work is closely related to the work of @ cite , where the back of a neural network is used to generate a cascade of the image .
 in this work , we focus on the problem of identifying a training set of layers in the context of networks .
 in @ cite the authors propose a sequential optimization approach based on the greedy algorithm , which is able to train a cascade classifier .
 a similar technique is used in the work by @ cite .
 this approach is similar to our approach , but the latter is based on locking rather than stacking the locking problem: .
 in contrast , our approach does not require a large amount of training data , and is not straightforward to adapt to a large number of layers .
 we believe that our approach can be seen as an extension of our work , and we introduce a novel generalization of the joint training phase .
 we show that the back propagation algorithm outperforms @ cite and @ cite for face detection and inefficiency of the training set , in which a small subset of the network is known .
 the difference between our approach and the previous work is that we are able to achieve the best of our approach .

