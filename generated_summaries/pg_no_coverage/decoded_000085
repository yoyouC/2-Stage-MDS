deep convolutional neural networks ( cnns ) have been widely used in deep learning frameworks @ cite @ cite .
 in this work , we focus on the problem of representation learning for imbalanced data learning and clustering in a single unsupervised setting .
 in @ cite , the authors propose a ensemble method, based approach to learn a Mahalanobis distance metric for kNN classification .
 @ cite propose a novel loss function to impose constraints on the loss of maximum margin constraints .
 their method is based on the assumption that the minority classes are separated into a large number of classes .
 in contrast , our work focuses on learning discriminative deep representation learning , which is different to our work .
 we use a similar idea of @ cite to learn multiple imbalanced data , where each norm is assumed to be drawn from each epoch .
 the first class membership problem is solved by learning a decision forest from an ensemble of a deep network and the hidden units of rbms ( e.
g over element-wise multiplication ) @ math , @ math and @ math .
 the goal is to minimize the kullback-leibler divergence @ math of @ math ( where @ math is the number of layers ) .
 generative adversarial networks ( gans ) have been used in the context of deep learning @ cite @ cite .
 in this work , we focus on selecting instances from the majority of the minority classes @ cite and the majority class.
 The performance @ cite , which is based on the assumption that the data of classes can be inferred from the unlabeled data .
 in @ cite the authors propose a data augmentation method to learn the maximum margin constraints .
 they show that the selection technique outperforms the accuracy of a logistic regression classifier .
 @ cite used a similar loss function to improve the performance of the classifier .
 however , this approach does not scale up to a few hundreds of thousands and infrequent factors that are not available .
 in contrast , our approach is different from ours , since it is not clear how to minimize the discrepancy between the prototypes of the affinity matrix .
 our work is different to the work of @ cite who tackled the problem of aligning imbalanced data with multiple object classes in the presence of multiple biological imbalanced domains , and @ cite studied the classification of a imbalanced class imbalance problem .

