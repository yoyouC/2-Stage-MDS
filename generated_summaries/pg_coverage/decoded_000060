recently , a large number of works have been proposed to estimate the pose of a monocular camera @ cite @ cite .
 however to the best of our knowledge , there is no prior work on real-time visual odometry in dynamic environments .
 for example , @ cite proposed a method for estimating the motion of an RGB-D camera based on the estimated background model .
 in @ cite , a visual odometry algorithm is used to detect the pose and motion of the sensor .
 @ cite propose a method to jointly estimate the ego-motion and motion capture of motion and motion model .
 however between the static and dynamic parts of the self-collected data , the proposed method is able to distinguish the tracked camera motion from self-collected images to the temporal motion hypotheses .
 in contrast to our approach , our approach integrates inertial capture mechanical and dynamic rigid segmentation with the region of parts , as well as the energy-based estimation of the pose estimation of several motion hypotheses and the motion capture in dynamic scene flow .
 our approach is complementary to this work in the sense that the motion tracking is tightly coupled with advantage of the camera motions .
 the deblurring problem has received a lot of interest in the area of visual odometry and dynamic environments @ cite @ cite .
 in @ cite , a stereo camera is used to estimate the pose of a monocular camera .
 @ cite proposed a visual odometry scheme based on a lidar camera placed on the centroids of the camera to the angular plane .
 the non-binary moving pixels were estimated using a kalman filter detector @ cite and the kalman filter @ cite are used to track the pose and the motion of the foreground objects .
 the proposed method is able to recognize the scene and predict the number of observed independent locations of the video in the temporal motion tracking .
 in contrast to our work , we use self-collected data for spatial motion segmentation and clusters of motion hypotheses .
 our approach is based on the use of spatial and temporal information for real-time visual odometry .
 however until recently , there is a large body of work on anomaly detection in dynamic scene flow segmentation .
 in particular , @ cite use a stereo camera.
 camera to detect anomalies in general dynamic scenes .
 however , this approach does not address the problem of occluded objects .
 in the area of visual odometry , the motion of a camera has been addressed in the context of slam @ cite @ cite .
 in this work , we use self-collected data to detect the pose of a visual odometry system .
 @ cite proposed a learning-based approach based on a large margin on the localization of the optical flow and the motion capture of the motion boundaries .
 in @ cite , the authors proposed a method based on the ground-truth pose of the skeleton , which is then used to predict motion hypotheses .
 however by @ cite the authors did not consider the performance of the grid-based scene flow.
 proposed in this paper , as well as the MPI-Sintel @ cite and computationally efficient approaches for real-time visual odometry and rigid motion segmentation .
 in contrast to our approach , this approach has been applied to motion tracking in dynamic environments , which can be seen as a special case of the temporal motion tracking problem .
 however and in contrast , our approach is able to estimate the pose and the pose estimation of the static parts of the self-collected data , and the latter is not suitable for spatial angular motions .
 the problem of spatial motion in dynamic environments has received a lot of attention in recent years @ cite @ cite .
 @ cite proposed a method for real-time static dynamic segmentation of dynamic objects using self-collected images .
 however by @ cite , @ cite and @ cite use inertial sensors for online dynamic segmentation .
 however , these methods are not suitable for real-time visual odometry , because they do not track the pose of a camera .
 however parts of the camera are not available in the temporal motion tracking pipeline .
 in contrast , our approach does not require a large amount of visual cues to capture the motion hypotheses and motion capture the temporal dynamics of the motion .
 in our work , we aim to detect the dynamic body motion between several dynamic objects and the camera motion , and the motion model is used to estimate the position of a body shape of a static scene mounted on a self-supervised scene flow field .
 our approach is similar in spirit to the present work in the sense that rigid flow and optical flow can be used to track the labels of a monocular image .

