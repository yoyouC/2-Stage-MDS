neural network-based methods have been proposed for the access control literature @ cite @ cite .
 for example , @ cite proposed a method based on a hybrid bidirectional LSTM ( [UNK] ) to identify and detects multiple, word- and character-level features .
 @ cite use a hybrid approach to predict entity co-occurrences for a given set of entity names .
 the work of @ cite extends the work by @ cite and @ cite , who used a balanced lexicon for entity disambiguation .
 however to the best of our knowledge , none of these works have focused on the problem of provenance data provenance , which are not available in the context of access control .
 in contrast to our work , we use local information captured from different sources of feature extraction and partial disambiguated linking .
 our approach differs from theirs in two aspects : 1 ) we are able to operate on the CoNLL-2003 of the physical storage , which is the focus of our work .
 in our experiments , we expand the mutual dependency between the components of the disambiguated It .
 we show that feature extraction data can be used to improve the performance of the system .
 there has been extensive prior work on semantic parsing in the context of knowledge bases , such as entity linking @ cite @ cite and question answering @ cite .
 for example , @ cite proposed a method to predict entities in the knowledge base .
 @ cite propose a linking model based on a knowledge base system to identify the relationships between pairs of knowledge base triples .
 the work of @ cite uses a graph model to rank descriptions of the entity pair from a corpus of entities.
 The entity pairs .
 the authors in @ cite use a similar approach to @ cite for the task of question answering , where the authors consider the problem of jointly embedding the sentences into a logical form.
 node and the relationship between the most frequent words and the sentences .
 in contrast to our work , our approach is based on the commonly used knowledge bases for each entity in the graph , and try to optimize the search space of the knowledge graph .
 our work differs from the previous work in the area of knowledge extraction , rather than being able to address the disambiguation problem .
 in particular , we propose a novel degree-based measures based on graph connectivity.
 Experimental .
 there is a large body of work on entity linking , such as @ cite @ cite , @ cite and @ cite .
 in the context of entity disambiguation , a tree-based structured learning approach was proposed in @ cite for the task of entity linking .
 @ cite proposed a neural network for word-based entity identification using multiple additive regression .
 the authors of @ cite used a graph model to classify the fragments of the words in the corpus of entities.
 The .
 however to the best of our knowledge , none of these approaches have been proposed in the literature .
 in our work , we focus on the semantic relation between context and the context information in the distance between the context vectors and the candidate name entities in the perspectives, space .
 in this paper , we propose a novel architecture based on multiple additive vector space and word-level document from multiple perspectives, documents .
 in addition to the use of a hand-crafted feature vector , we use a bow model to extract features of the context vector of the document , which is then fed into an svm classifier to predict the next word .
 there are two main types of social media analytics systems , such as Entity @ cite , [UNK] @ cite @ cite and Certus, @ cite .
 the most relevant work is the work of @ cite which uses a graph-based approach to segment and segment the entities in the head entity .
 @ cite present a comprehensive review on continuous data.
 Therefore, , with a focus on modeling the relationship between entities and documents .
 in this work , we focus on the task of parent-child relations between the head and entity entity in a knowledge base , rather than the context of the entity linking task .
 our work differs from the area of research in the field of knowledge computing and identification of neural networks .
 in particular , we use the knowledge graph model to represent the knowledge of the entities of the graph , and the outputs of the head are modeled as the type of symbolic information .
 in contrast to our work , the knowledge between knowledge bases and the tail is available in the social domain is not available .
 in addition , our approach is able to learn a classifier to respect the head to the tail entity.
 .
 there is a large literature on transfer learning for knowledge bases , such as Wikipedia.
 @ cite , [UNK] @ cite @ cite and ccg @ cite .
 in the context of knowledge , there are two main types of relation extraction approaches , which are related to our work .
 for example , @ cite propose a relation linking technique based on collaborative filtering for maximizing the global interdependence between the entities in the target system .
 @ cite use active learning to optimize the correspondence between relation patterns and the referent entities in a knowledge base model .
 the authors of @ cite proposed a generative model based on a semantic-based criterion to capture the structural properties of knowledge encoded on recommender systems .
 however like @ cite the authors in this paper , we aim to learn the correspondences between knowledge encoded and a semantic-based index , which constructed the entities of different values in the source and target system.
 ( i.
e.
 high-probability ) , the actively observed entities ( i.
e.
 across different systems ) , i.
e.
 that can be used to build a relation between the source system and the source of the relation between entities .

